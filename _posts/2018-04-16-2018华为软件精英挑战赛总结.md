---
title: 2018华为软件精英挑战赛总结
tags: python
key: 20180416
---

这次比赛还是有挺大遗憾的，由于算法中随机部分的影响，导致在大数据量情况下最终结果不稳定，最后一版提交分数远不如最高分，而赛制又是取最后一次的分数，最终未能进入复赛。

本总结技术指导性很低，一是因为比赛的确挺玄学，大部分高分也是通过调参调出来的；二是自己也并未用到高技术含量的东西，都是常用模型与常见算法。主要是自己的一些小思考。

不忍还要吐槽一下，一模一样的代码跑了三个分数出来，而且还是一次比一次低。在最后仅有两次提交机会的时候，决定提交之前最高分数的版本，提交完毕系统跑分结果出来的一刹那有点吃惊，因为在练习阶段此代码的的评分从未波动过，但这分数是肯定不会进复赛（前36）的，
于是跟队友商量后，前64对我们没有任何意义，于是决定对算法运行时间稍作限制（其他均未有变动）再提交一次，结果彻底崩溃，又降了接近10分......
就此用完十次机会，将近一个月的辛苦就这样有点讽刺意味的白费了（白费一词可能需要再斟酌一下，毕竟还是有所收获的，而且之前最高分也不一定就能进复赛，而我现在已经不想再看）。
<!--more-->

在练习赛阶段的最高名次曾到达赛区（上合）第5。

![image](https://github.com/kanyuanzhi/kanyuanzhi.github.io/raw/master/assets/myimages/20180416205144.jpg)

## 赛题介绍

本次比赛主要分为两部分，预测+放置，根据历史数据预测下一时间段的虚拟机请求数以及在预测的结果上将虚拟机放置在物理服务器中使得物理服务器的利用率最大。其他信息可参考官网（<http://codecraft.devcloud.huaweicloud.com/home/detail>），在此不再赘述。

## 预测

首先要说明的是这个比赛不允许使用任何第三方库，所以一些开源的机器学习，深度学习的框架是没法使用的，甚至是numpy都不能使用，当然矩阵运算也不是很复杂，但是自己写的速度上肯定比不上numpy。

### 尝试模型

预测部分是一个典型的时间序列建模预测问题，有很多经典的模型可以使用，比如线性回归、指数平滑、GARCH、ARIMA、回归树，随机森林甚至是GBDT等等，深度学习中的循环神经网络（LSTM）也是解决序列建模的利器，但手撸LSTM困难还是比较大的，个人也是水平有限。

我们在练习阶段尝试了如下几种方法：线性自适应，BP网络，线性回归，一阶指数平滑，二阶指数平滑。这些都非常简单而且易于实现，而且对于预测问题，也并不是模型越复杂就越好。
现在回顾整个比赛，觉得最欠缺的还是原始数据处理部分。如果数据处理的好，简单地模型也会取得很好地预测效果，

线性回归、线性自适应相当于在解一个Y=WX+b方程，通过近期数据的线性组合来预测出下一期数据。
这个效果并不是很好，首先是训练集的划分很难平衡X的维度与整体数据量的关系（或者说是方程数与待求变量数的关系），很容易造成解不唯一但都符合训练集的误差要求。

在学习过程中了解过正则化，通过对线性回归加一个正则项，将解集限定在一定范围内来避免过拟合的问题，如岭回归与lasso回归，此处并未深入学习。

BP网络通过加了一层神经元使得其可以逼近任意非线性函数，这也跳出了线性模型的线性限制，但同样存在数据集的划分问题，每次训练后权值都不一样，但对训练集都可以完美拟合。
此外BP网络的训练收敛速度也是一个问题所在。

对于指数平滑，则是一个相当具有普适性的预测方法了。一阶指数平滑主要针对无规律的序列，二阶指数平滑针对有趋势的序列，三阶指数平滑则针对季节性明显的序列。
结合本次比赛，通过对训练集的数据绘图，肉眼并未观察到任何规律所在，甚至怀疑题目是否可以建模预测。实际代码中使用了一阶与二阶指数平滑，一阶对单个时间段内的请求数建模，
二阶对单个时间段内的累积请求数建模。调参上则是手动不断尝试，曾使用过自动调参，通过遍历参数值计算训练集的拟合程度来决定参数，但最终效果不太理想。
最后最高分版本使用的是一阶指数平滑，参数已经调到1.1，正常范围是0~1，这说明预测数据对最后一天的依赖更大。还有一种说法是参数大于1之后应该用更高阶的指数平滑来分析，
但同样二阶的效果并不好，可能是跟参数没有调好有关系，总之这里的调参非常玄学。

### 其他模型

