---
title: 2018华为软件精英挑战赛总结
tags: 机器学习
key: 20180416
---

这次比赛还是有挺大遗憾的，由于算法中随机部分的影响，导致在大数据量情况下最终结果不稳定，最后一版提交分数远不如最高分，而赛制又是取最后一次的分数，最终未能进入复赛。

本总结技术指导性很低，一是因为比赛的确挺玄学，大部分高分也是通过调参调出来的；二是自己也并未用到高技术含量的东西，都是常用模型与常见算法。主要是自己的一些小思考。

不忍还要吐槽一下，一模一样的代码跑了三个分数出来，而且还是一次比一次低。在最后仅有两次提交机会的时候，决定提交之前最高分数的版本，提交完毕系统跑分结果出来的一刹那有点吃惊，因为在练习阶段此代码的的评分从未波动过，但这分数是肯定不会进复赛（前36）的，
于是跟队友商量后，前64对我们没有任何意义，决定对算法运行时间稍作限制（其他均未有变动）再提交一次，结果彻底崩溃，又降了接近10分......
就此用完十次机会，将近一个月的辛苦就这样有点讽刺意味的白费了（白费一词可能需要再斟酌一下，毕竟还是有所收获的，而且之前最高分也不一定就能进复赛，而我现在已经不想再看）。
<!--more-->

在练习赛阶段的最高名次曾到达赛区（上合）第5。

![image](https://github.com/kanyuanzhi/kanyuanzhi.github.io/raw/master/assets/myimages/20180416205144.jpg)

## 赛题介绍

本次比赛主要分为两部分，预测+放置，根据历史数据预测下一时间段的虚拟机请求数以及在预测的结果上将虚拟机放置在物理服务器中使得物理服务器的利用率最大。其他信息可参考官网（<http://codecraft.devcloud.huaweicloud.com/home/detail>），在此不再赘述。

## 预测

首先要说明的是这个比赛不允许使用任何第三方库，所以一些开源的机器学习，深度学习的框架是没法使用的，甚至是numpy都不能使用，当然矩阵运算也不是很复杂，但是自己写的速度上肯定比不上numpy。

### 尝试模型

预测部分是一个典型的时间序列建模预测问题，有很多经典的模型可以使用，比如线性回归、指数平滑、GARCH、ARIMA、回归树，随机森林甚至是GBDT等等，深度学习中的循环神经网络（LSTM）也是解决序列建模的利器，但手撸LSTM困难还是比较大的，个人也是水平有限。

我们在练习阶段尝试了如下几种方法：线性自适应，BP网络，线性回归，一阶指数平滑，二阶指数平滑。这些都非常简单而且易于实现，而且对于预测问题，也并不是模型越复杂就越好。
现在回顾整个比赛，觉得最欠缺的还是原始数据处理部分。如果数据处理的好，简单地模型也会取得很好地预测效果，

线性回归、线性自适应相当于在解一个Y=WX+b方程，通过近期数据的线性组合来预测出下一期数据。
这个效果并不是很好，首先是训练集的划分很难平衡X的维度与整体数据量的关系（或者说是方程数与待求变量数的关系），很容易造成解不唯一但都符合训练集的误差要求。

在学习过程中了解过正则化，通过对线性回归加一个正则项，将解集限定在一定范围内来避免过拟合的问题，如岭回归与lasso回归，此处并未深入学习。

BP网络通过加了一层神经元使得其可以逼近任意非线性函数，这也跳出了线性模型的线性限制，但同样存在数据集的划分问题，每次训练后权值都不一样，但对训练集都可以完美拟合。
此外BP网络的训练收敛速度也是一个问题所在。

对于指数平滑，则是一个相当具有普适性的预测方法了。一阶指数平滑主要针对无规律的序列，二阶指数平滑针对有趋势的序列，三阶指数平滑则针对季节性明显的序列。
结合本次比赛，通过对训练集的数据绘图，肉眼并未观察到任何规律所在，甚至怀疑题目是否可以建模预测。实际代码中使用了一阶与二阶指数平滑，一阶对单个时间段内的请求数建模，
二阶对单个时间段内的累积请求数建模。调参上则是手动不断尝试，曾使用过自动调参，通过遍历参数值计算训练集的拟合程度来决定参数，但最终效果不太理想。
最后最高分版本使用的是一阶指数平滑，参数已经调到1.1，正常范围是0~1，这说明预测数据对最后一天的依赖更大。还有一种说法是参数大于1之后应该用更高阶的指数平滑来分析，
但同样二阶的效果并不好，可能是跟参数没有调好有关系，总之这里的调参非常玄学。

### 其他模型

以上提到的其他模型仅有考虑但并未代码实现。ARIMA通过差分运算，将非平稳序列转变为平稳序列而后进行分析，对于练习赛数据，
不管是一阶差分还是二阶差分均不能将原序列转化为平稳序列，因此未使用ARIMA。GARCH则是针对波动率聚集现象进行建模，简单表述为
“大波接大波，小波接小波”，通过观察原序列也并未发现有此规律。以上仅凭肉眼排除使用ARIMA与GARCH，可能有欠考虑，如果进复赛
是会尝试这两个模型，尤其是GARCH。由于代码中并未使用到此两种模型，故也未做更深入的学习。

回归树是决策树的一种，用以解决回归问题，通过CART算法构建，核心通过使平方误差最小化来寻找最优切分特征与最优切分点，
其训练集划分也与线性回归模型有些类似，若干维度的X预测下一期值。但回归树建完后规模通常过大，造成过拟合，这可以通过剪枝来进一步优化，
但回归树是否真的适合时间序列分析也是值得商榷的，比赛后期考虑回归树可能有点病急乱投医的意思了。此处也准备在之后做更系统的学习。

至于随机森林与GBDT，则完全是一种理想中的方法。一来自己本身机器学习的基础并不扎实，难以不依赖第三方库来实现它们；二来即使可以实现，
其训练效率上肯定也是一个很大的问题。而LSTM则更是一种只能难以白手实现的方法了，争取在之后的学习中熟悉了解并实现它们。

### 小结

总体上比赛的预测部分还是需要有一定机器学习基础的，如果之前就有写过一些经典的训练方法，此时完全可以拿出来使用。对于我们这些
现学现写的，还是只能尝试一些简单的模型。

之前有收到原始数据预处理的问题，这点应该是最需要好好反思的。训练数据中由于节假日的存在，造成某一天的请求量异常，还有其他非节假日的
噪点存在，怎么处理这些噪点？在代码中我们仅仅用周围的平均值来取代原始节假日的请求数，而对整体则通过高斯去噪进行特别粗劣的平滑处理，
高斯去噪的参数也是不断手动尝试。这方面可在之后多补从补充数据挖掘相关的知识。