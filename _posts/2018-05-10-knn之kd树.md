---
title: knn之kd树
tags: ML
key: 20180510
---

knn最简单的实现方法是现行扫描，即计算所有实例两两之间的距离。当训练集很大时，这种计算非常耗时。
用kd树存储数据集，可以减少计算代价。
<!--more-->

原理部分可参考这篇文章： <https://zhuanlan.zhihu.com/p/23966698>

## kd树的构建

### 算法
设数据有n维（1，2，3，4，...，n）

1. 构造根节点，深度为1，选择维度1上的中位数m1为切分点，比m1小的在根节点左边，比m1大的在根节点右边；
2. 重复，对于深度j，选择维度(j%n)上的中位数mj为切分点，比mj小的在节点左边，比mj大的在节点右边。

### 源码：

{% codeblock [lang:python] [linenos:true] %}
def __create(self, a, j):
    """
    递归生成kd树
    :param a: 待划分数据集
    :param j: 选择划分维度
    :return:
    """
    if len(a) == 1:
        a[0]['dimension'] = j
        return Node(a[0])
    else:
        middle_a = self.__midian(a, j)
        middle_index = len(a) / 2
        middle_a['dimension'] = j
        root_node = Node(middle_a)

        left_a = a[:middle_index]
        right_a = a[middle_index + 1:]

        left_node = self.__create(left_a, (j + 1) % self.dimensions)
        left_node.location = 'left'
        root_node.left = left_node
        left_node.parent = root_node

        if len(a) > 2:  # or len(right_a)>0，此处由于偶数长度序列取中位数时取的是中间两个数中右侧的一个，导致右序列可能为空
            right_node = self.__create(right_a, (j + 1) % self.dimensions)
            right_node.location = 'right'
            root_node.right = right_node
            right_node.parent = root_node

        return root_node
{% endcodeblock %}


## kd树的搜索


